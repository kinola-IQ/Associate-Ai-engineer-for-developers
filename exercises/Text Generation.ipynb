{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "#Api key\n",
    "client = OpenAI(api_key = 'Api key')\n",
    "\n",
    "#car marketing generation prompt\n",
    "prompt = '''\n",
    "Generate a snazy , cool,  and catchy slogan for a car brand whose mission is to\n",
    "manufacture cars that resonates with the youths bright and exuberant generation\n",
    "'''\n",
    "#generate response\n",
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-4o-mini',\n",
    "    messages = [\n",
    "        {\n",
    "            'role':'user',\n",
    "            'content': prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature = 1.5, #control the degree of randomness for generated responses\n",
    "    max_completion_tokens = 50 #control the lenght of generated responses\n",
    ")\n",
    "\n",
    "#output\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "'''\n",
    "Note that lower temperature values make the output more focused and deterministic, while higher values increase randomness and creativity.\n",
    "also note that higher max_tokens values allow for longer responses, but may also increase the risk of generating irrelevant or off-topic content.\n",
    "and as so when adjusting the max_tokens, it may be necessary to also adjust the temperature to maintain a balance between creativity and relevance.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PowerShell",
   "language": "powershell",
   "name": "powershell"
  },
  "language_info": {
   "name": "powershell"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
